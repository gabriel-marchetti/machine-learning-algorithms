{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e4db537",
   "metadata": {},
   "source": [
    "# Testing aspects of Minimax Group Fairness\n",
    "URL: https://arxiv.org/abs/2011.03108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19d554",
   "metadata": {},
   "source": [
    "Try simulate \"Two-Player Game Formulation\" proposed by the article to see how i can fit it under the package Temis.\n",
    "\n",
    "GENERAL DESCRIPTION:\n",
    "\n",
    "Regulator: Tries to identify which group has great loss and increase it's weight through exponential weights.\n",
    "\n",
    "Learner: Minimize current model and seek for optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d338dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9890b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimaxFairness:\n",
    "    def __init__(self, model_class, iterations=100, lr=0.5, verbose=False):\n",
    "        self.model_class = model_class\n",
    "        self.T = iterations\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Initialize storage for models, lambdas, and group losses history\n",
    "        self.models = []\n",
    "        self.lambdas_history = []\n",
    "        self.group_losses_history = []\n",
    "    def fit(self, X, y, groups):\n",
    "        if self.verbose == True:\n",
    "            print(f\"Debugging fit information...\")\n",
    "        n_samples = len(y)\n",
    "\n",
    "        unique_groups = np.unique(groups)\n",
    "        n_groups = len(unique_groups)\n",
    "        if self.verbose == True:\n",
    "            print(f\"Number identified groups: {n_groups}\")\n",
    "            print(f\"Identified Groups: {unique_groups}\")\n",
    "\n",
    "        group_counts = {g: np.sum(groups == g) for g in unique_groups}\n",
    "\n",
    "        if self.verbose == True:\n",
    "            print(f\"Group Counts: {group_counts}\")\n",
    "\n",
    "        self.lambdas = {g: group_counts[g] / n_samples for g in unique_groups}\n",
    "\n",
    "        if self.verbose == True:\n",
    "            print(f\"Initial Lambdas: {self.lambdas}\")\n",
    "\n",
    "        if self.verbose == True:\n",
    "            print(f\"Initializing game with {self.T} rounds...\")\n",
    "            \n",
    "        sample_weights = np.zeros(n_samples)\n",
    "        for g in unique_groups:\n",
    "            mask = (groups == g)\n",
    "            sample_weights = self.lambdas[g]\n",
    "\n",
    "        for t in range(1, self.T + 1):\n",
    "            if self.verbose == True:\n",
    "                print(f\"Initialing round: {t}\")\n",
    "\n",
    "            #h_t = self.model_class(solver='lbfgs', max_iter=100)\n",
    "            h_t = clone(self.model_class)\n",
    "            h_t.fit(X, y, sample_weight=sample_weights)\n",
    "            self.models.append(h_t)\n",
    "\n",
    "            group_losses = {}\n",
    "            probs = h_t.predict_proba(X)\n",
    "\n",
    "            for g in unique_groups:\n",
    "                mask = (groups == g)\n",
    "                loss_k = log_loss(y[mask], probs[mask])\n",
    "                group_losses[g] = loss_k\n",
    "\n",
    "            self.group_losses_history.append(group_losses)\n",
    "            self.lambdas_history.append(self.lambdas.copy())\n",
    "\n",
    "            for g in unique_groups:\n",
    "                self.lambdas[g] *= np.exp(self.lr * group_losses[g])\n",
    "    def predict_proba(self, X):\n",
    "        if self.verbose == True:\n",
    "            print(f\"debugging predict_proba information....\")\n",
    "        preds = np.array([h.predict_proba(X) for h in self.models])\n",
    "        mean_preds = np.mean(preds, axis=0)\n",
    "        return mean_preds\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb60a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline (Standard Logistic Regression) ---\n",
      "Log Loss Grupo 0: 0.4144\n",
      "Log Loss Grupo 1: 0.8712\n",
      "Diferença de Erro: 0.4568\n",
      "\n",
      "--- Minimax Fair Model (Após 10 iterações) ---\n",
      "Log Loss Grupo 0: 0.4148\n",
      "Log Loss Grupo 1: 0.8703\n",
      "Diferença de Erro: 0.4555\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "np.random.seed(random_state)\n",
    "n_samples = 1000\n",
    "X, y = make_classification(n_samples=n_samples, n_features=20, n_informative=10, n_redundant=10, random_state=random_state)\n",
    "groups = np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])\n",
    "\n",
    "# Add noise to some group to make it harder to guess.\n",
    "noise_idxs = np.where(groups == 1)[0]\n",
    "y[noise_idxs] = np.random.choice([0, 1], size=len(noise_idxs))\n",
    "\n",
    "# Add some baseline model and test error rates.\n",
    "baseline_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "baseline_model.fit(X, y)\n",
    "baseline_preds = baseline_model.predict(X)\n",
    "#print(baseline_model.coef_)\n",
    "\n",
    "baseline_loss_class_0 = log_loss(y[groups == 0], baseline_model.predict_proba(X)[groups == 0])\n",
    "baseline_loss_class_1 = log_loss(y[groups == 1], baseline_model.predict_proba(X)[groups == 1])\n",
    "\n",
    "print(\"--- Baseline (Standard Logistic Regression) ---\")\n",
    "print(f\"Log Loss Grupo 0: {baseline_loss_class_0:.4f}\")\n",
    "print(f\"Log Loss Grupo 1: {baseline_loss_class_1:.4f}\")\n",
    "print(f\"Diferença de Erro: {abs(baseline_loss_class_0 - baseline_loss_class_1):.4f}\")\n",
    "\n",
    "# Add Minimax Fairness model and test error rates.\n",
    "n_iter = 10\n",
    "mm_model_class = LogisticRegression(solver='lbfgs', max_iter=100)\n",
    "mm_model = MinimaxFairness(mm_model_class, iterations=n_iter, lr=0.5, verbose=False)\n",
    "mm_model.fit(X, y, groups)\n",
    "\n",
    "mm_pred_probs = mm_model.predict_proba(X)\n",
    "mm_pred_y0 = mm_pred_probs[:, 0]\n",
    "mm_pred_y1 = mm_pred_probs[:, 1]\n",
    "mm_loss_class_0 = log_loss(y[groups == 0], mm_pred_y1[groups == 0])\n",
    "mm_loss_class_1 = log_loss(y[groups == 1], mm_pred_y1[groups == 1])\n",
    "\n",
    "print(f\"\\n--- Minimax Fair Model (Após {n_iter} iterações) ---\")\n",
    "print(f\"Log Loss Grupo 0: {mm_loss_class_0:.4f}\")\n",
    "print(f\"Log Loss Grupo 1: {mm_loss_class_1:.4f}\")\n",
    "print(f\"Diferença de Erro: {abs(mm_loss_class_0 - mm_loss_class_1):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8d2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
