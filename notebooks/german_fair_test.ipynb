{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11172c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30010963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from Temis.LogisticRegression import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression as SklearnLR\n",
    "\n",
    "# ---------------------------------- #\n",
    "# These metrics will be replaced with the ones from sklearn.\n",
    "# from Temis.metrics.accuracy import compute_accuracy\n",
    "# from Temis.metrics.precision import compute_precision\n",
    "# from Temis.metrics.recall import compute_recall\n",
    "# from Temis.metrics.f1_score import compute_f1\n",
    "# ---------------------------------- #\n",
    "from Temis.metrics.brier_score import compute_brier\n",
    "from Temis.fairness_metrics.spd import compute_spd\n",
    "from Temis.fairness_metrics.dir import compute_dir\n",
    "from Temis.fairness_metrics.aod import compute_aod\n",
    "from Temis.fairness_metrics.aaod import compute_aaod\n",
    "\n",
    "from Temis.comparison_utils.cmp_fairness import compare_fairness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68235be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Temis.LogisticRegression' from 'E:\\\\Faculdade\\\\2025_2s\\\\machine-learning-algorithms\\\\Temis\\\\LogisticRegression.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import Temis.LogisticRegression\n",
    "importlib.reload(Temis.LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d908be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data from: ..\\datasets\\german\\german.data-numeric\n",
      "Data imported successfully\n"
     ]
    }
   ],
   "source": [
    "path_dataset = os.path.join('..', 'datasets', 'german', 'german.data-numeric')\n",
    "col_names = [f'feature_{i}' for i in range(1,25)] + ['label']\n",
    "\n",
    "try:\n",
    "    print(f'Importing data from: {path_dataset}')\n",
    "    df = pd.read_csv(\n",
    "        path_dataset,\n",
    "        header=None,\n",
    "        sep='\\s+',\n",
    "        engine='python',\n",
    "        names=col_names\n",
    "    )\n",
    "    print(f'Data imported successfully')\n",
    "except FileNotFoundError:\n",
    "    print('Failed importing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1a177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=['label']).to_numpy(),\n",
    "    df['label'].to_numpy(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "''' \n",
    "Correcting dataset labels from {1, 2} to {0, 1}.\n",
    "'''\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a741c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "Gradient Magnitude - dw: 0.1811642348766327\n",
      "Gradient Magnitude - db: 0.02542928233742714\n",
      "Epoch: 10\n",
      "Gradient Magnitude - dw: 0.4015483260154724\n",
      "Gradient Magnitude - db: 0.06287898123264313\n",
      "Epoch: 20\n",
      "Gradient Magnitude - dw: 0.24536924064159393\n",
      "Gradient Magnitude - db: 0.0889991819858551\n",
      "Epoch: 30\n",
      "Gradient Magnitude - dw: 0.1859787106513977\n",
      "Gradient Magnitude - db: 0.028526149690151215\n",
      "Epoch: 40\n",
      "Gradient Magnitude - dw: 0.41344237327575684\n",
      "Gradient Magnitude - db: 0.08597181737422943\n",
      "Epoch: 50\n",
      "Gradient Magnitude - dw: 0.6627362370491028\n",
      "Gradient Magnitude - db: 0.1577656865119934\n",
      "Epoch: 60\n",
      "Gradient Magnitude - dw: 0.3165484666824341\n",
      "Gradient Magnitude - db: 0.04999595135450363\n",
      "Epoch: 70\n",
      "Gradient Magnitude - dw: 0.11234809458255768\n",
      "Gradient Magnitude - db: 0.008686643093824387\n",
      "Epoch: 80\n",
      "Gradient Magnitude - dw: 0.5107420682907104\n",
      "Gradient Magnitude - db: 0.08645756542682648\n",
      "Epoch: 90\n",
      "Gradient Magnitude - dw: 0.29226863384246826\n",
      "Gradient Magnitude - db: 0.0674394965171814\n"
     ]
    }
   ],
   "source": [
    "model_fair = LogisticRegression(lr=0.001, epochs=100, penalty='l2', penalty_weight=1.0, fair_penalty='Rpr', fair_penalty_weight=10.0)\n",
    "model_fair.fit(X_train, y_train, S = X_train[:, 15], debug = True)\n",
    "fair_pred_test = model_fair.predict(X_train)\n",
    "fair_prob_test = model_fair.predict_probability(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b434fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "Gradient Magnitude - dw: 0.5779361128807068\n",
      "Gradient Magnitude - db: 0.11387259513139725\n",
      "Epoch: 10\n",
      "Gradient Magnitude - dw: 0.30837875604629517\n",
      "Gradient Magnitude - db: 0.05851151794195175\n",
      "Epoch: 20\n",
      "Gradient Magnitude - dw: 0.46353089809417725\n",
      "Gradient Magnitude - db: 0.05814595893025398\n",
      "Epoch: 30\n",
      "Gradient Magnitude - dw: 0.2165900319814682\n",
      "Gradient Magnitude - db: 0.02102816477417946\n",
      "Epoch: 40\n",
      "Gradient Magnitude - dw: 0.8895630836486816\n",
      "Gradient Magnitude - db: 0.14116643369197845\n",
      "Epoch: 50\n",
      "Gradient Magnitude - dw: 0.5347052812576294\n",
      "Gradient Magnitude - db: 0.040967077016830444\n",
      "Epoch: 60\n",
      "Gradient Magnitude - dw: 0.9602672457695007\n",
      "Gradient Magnitude - db: 0.1775478720664978\n",
      "Epoch: 70\n",
      "Gradient Magnitude - dw: 0.4313814342021942\n",
      "Gradient Magnitude - db: 0.05994608253240585\n",
      "Epoch: 80\n",
      "Gradient Magnitude - dw: 0.2351866066455841\n",
      "Gradient Magnitude - db: 0.0010108258575201035\n",
      "Epoch: 90\n",
      "Gradient Magnitude - dw: 0.1753847450017929\n",
      "Gradient Magnitude - db: 0.02991355210542679\n"
     ]
    }
   ],
   "source": [
    "model_not_fair = LogisticRegression(lr=0.001, epochs=100, penalty='l2', penalty_weight=1.0, fair_penalty='Rpr', fair_penalty_weight=0.0)\n",
    "model_not_fair.fit(X_train, y_train, S = X_train[:, 15], debug = True)\n",
    "not_fair_pred_test = model_not_fair.predict(X_train)\n",
    "not_fair_prob_test = model_not_fair.predict_probability(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72453fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "Gradient Magnitude - dw: 0.4447218179702759\n",
      "Gradient Magnitude - db: 0.11646933853626251\n",
      "Epoch: 10\n",
      "Gradient Magnitude - dw: 1.9002001285552979\n",
      "Gradient Magnitude - db: 0.22531665861606598\n",
      "Epoch: 20\n",
      "Gradient Magnitude - dw: 1.1322040557861328\n",
      "Gradient Magnitude - db: 0.22229507565498352\n",
      "Epoch: 30\n",
      "Gradient Magnitude - dw: 0.1727854609489441\n",
      "Gradient Magnitude - db: 0.011097218841314316\n",
      "Epoch: 40\n",
      "Gradient Magnitude - dw: 0.16672305762767792\n",
      "Gradient Magnitude - db: 0.042769309133291245\n",
      "Epoch: 50\n",
      "Gradient Magnitude - dw: 1.8357433080673218\n",
      "Gradient Magnitude - db: 0.10701902210712433\n",
      "Epoch: 60\n",
      "Gradient Magnitude - dw: 0.5382842421531677\n",
      "Gradient Magnitude - db: 0.11099079251289368\n",
      "Epoch: 70\n",
      "Gradient Magnitude - dw: 1.668519377708435\n",
      "Gradient Magnitude - db: 0.060682713985443115\n",
      "Epoch: 80\n",
      "Gradient Magnitude - dw: 0.9916301965713501\n",
      "Gradient Magnitude - db: 0.17534077167510986\n",
      "Epoch: 90\n",
      "Gradient Magnitude - dw: 0.39436638355255127\n",
      "Gradient Magnitude - db: 0.11402489989995956\n"
     ]
    }
   ],
   "source": [
    "model_ultra_fair = LogisticRegression(lr=0.001, epochs=100, penalty='l2', penalty_weight=1.0, fair_penalty='Rpr', fair_penalty_weight=100.0)\n",
    "model_ultra_fair.fit(X_train, y_train, S = X_train[:, 15], debug = True)\n",
    "ultra_fair_pred_test = model_ultra_fair.predict(X_train)\n",
    "ultra_fair_prob_test = model_ultra_fair.predict_probability(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39d6688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "Gradient Magnitude - dw: 1.8475825786590576\n",
      "Gradient Magnitude - db: 0.4973689317703247\n",
      "Epoch: 10\n",
      "Gradient Magnitude - dw: 0.3995175063610077\n",
      "Gradient Magnitude - db: 0.020100586116313934\n",
      "Epoch: 20\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 30\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 40\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 50\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 60\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 70\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 80\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 90\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n"
     ]
    }
   ],
   "source": [
    "model_ultra_fair = LogisticRegression(lr=0.001, epochs=100, penalty='l2', penalty_weight=1.0, fair_penalty='Rpr', fair_penalty_weight=1000.0)\n",
    "model_ultra_fair.fit(X_train, y_train, S = X_train[:, 15], debug = True)\n",
    "ultra_fair_pred_test = model_ultra_fair.predict(X_train)\n",
    "ultra_fair_prob_test = model_ultra_fair.predict_probability(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22f33f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "Gradient Magnitude - dw: 2.604874610900879\n",
      "Gradient Magnitude - db: 0.5941992998123169\n",
      "Epoch: 10\n",
      "Gradient Magnitude - dw: 1.3174494504928589\n",
      "Gradient Magnitude - db: 0.2949525713920593\n",
      "Epoch: 20\n",
      "Gradient Magnitude - dw: 1.7541764974594116\n",
      "Gradient Magnitude - db: 0.08083391189575195\n",
      "Epoch: 30\n",
      "Gradient Magnitude - dw: 1.4695098400115967\n",
      "Gradient Magnitude - db: 0.21579609811306\n",
      "Epoch: 40\n",
      "Gradient Magnitude - dw: 2.26045560836792\n",
      "Gradient Magnitude - db: 0.43825024366378784\n",
      "Epoch: 50\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 60\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 70\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 80\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n",
      "Epoch: 90\n",
      "Gradient Magnitude - dw: nan\n",
      "Gradient Magnitude - db: nan\n"
     ]
    }
   ],
   "source": [
    "model_ultra_fair = LogisticRegression(lr=0.001, epochs=100, penalty='l2', penalty_weight=1.0, fair_penalty='Rpr', fair_penalty_weight=500.0)\n",
    "model_ultra_fair.fit(X_train, y_train, S = X_train[:, 15], debug = True)\n",
    "ultra_fair_pred_test = model_ultra_fair.predict(X_train)\n",
    "ultra_fair_prob_test = model_ultra_fair.predict_probability(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96859f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7348926283597711\n",
      "AUC: 0.7128022031042391\n",
      "AUC: 0.6843578114445625\n"
     ]
    }
   ],
   "source": [
    "print(f'AUC: {roc_auc_score(y_train, fair_prob_test)}')\n",
    "print(f'AUC: {roc_auc_score(y_train, not_fair_prob_test)}')\n",
    "print(f'AUC: {roc_auc_score(y_train, ultra_fair_prob_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5664a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 15:\n",
      "                Model Demographic Parity Equalized Odds\n",
      "0        Rpr Fairness                0.0            0.0\n",
      "1     Rpr No Fairness        0.057463318     0.09862956\n",
      "2  Rpr Ultra Fairness        0.066781685     0.10872246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Rpr Fairness\": model_fair,\n",
    "    \"Rpr No Fairness\": model_not_fair,\n",
    "    \"Rpr Ultra Fairness\": model_ultra_fair\n",
    "}\n",
    "\n",
    "results = compare_fairness(models, X_train, y_train, 15)\n",
    "print(f'Feature {15}:\\n{results}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db88366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      "Y=0,S=0: 443\n",
      "Y=0,S=1: 116\n",
      "Y=1,S=0: 167\n",
      "Y=1,S=1: 74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S = X_train[:, 15]\n",
    "y = y_train\n",
    "count_y0_s0 = jnp.sum((y == 0) & (S == 0))\n",
    "count_y0_s1 = jnp.sum((y == 0) & (S == 1))\n",
    "count_y1_s0 = jnp.sum((y == 1) & (S == 0))\n",
    "count_y1_s1 = jnp.sum((y == 1) & (S == 1))\n",
    "print(f'Counts:\\nY=0,S=0: {count_y0_s0}\\nY=0,S=1: {count_y0_s1}\\nY=1,S=0: {count_y1_s0}\\nY=1,S=1: {count_y1_s1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b570853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      "Y=0,S=0: 428\n",
      "Y=0,S=1: 146\n",
      "Y=1,S=0: 182\n",
      "Y=1,S=1: 44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S = X_train[:, 15]\n",
    "count_y0_s0 = jnp.sum((ultra_fair_pred_test == 0) & (S == 0))\n",
    "count_y0_s1 = jnp.sum((ultra_fair_pred_test == 0) & (S == 1))\n",
    "count_y1_s0 = jnp.sum((ultra_fair_pred_test == 1) & (S == 0))\n",
    "count_y1_s1 = jnp.sum((ultra_fair_pred_test == 1) & (S == 1))\n",
    "print(f'Counts:\\nY=0,S=0: {count_y0_s0}\\nY=0,S=1: {count_y0_s1}\\nY=1,S=0: {count_y1_s0}\\nY=1,S=1: {count_y1_s1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b829bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      "Y=0,S=0: 610\n",
      "Y=0,S=1: 190\n",
      "Y=1,S=0: 0\n",
      "Y=1,S=1: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S = X_train[:, 15]\n",
    "count_y0_s0 = jnp.sum((fair_pred_test == 0) & (S == 0))\n",
    "count_y0_s1 = jnp.sum((fair_pred_test == 0) & (S == 1))\n",
    "count_y1_s0 = jnp.sum((fair_pred_test == 1) & (S == 0))\n",
    "count_y1_s1 = jnp.sum((fair_pred_test == 1) & (S == 1))\n",
    "print(f'Counts:\\nY=0,S=0: {count_y0_s0}\\nY=0,S=1: {count_y0_s1}\\nY=1,S=0: {count_y1_s0}\\nY=1,S=1: {count_y1_s1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb5b696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts:\n",
      "Y=0,S=0: 530\n",
      "Y=0,S=1: 176\n",
      "Y=1,S=0: 80\n",
      "Y=1,S=1: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S = X_train[:, 15]\n",
    "count_y0_s0 = jnp.sum((not_fair_pred_test == 0) & (S == 0))\n",
    "count_y0_s1 = jnp.sum((not_fair_pred_test == 0) & (S == 1))\n",
    "count_y1_s0 = jnp.sum((not_fair_pred_test == 1) & (S == 0))\n",
    "count_y1_s1 = jnp.sum((not_fair_pred_test == 1) & (S == 1))\n",
    "print(f'Counts:\\nY=0,S=0: {count_y0_s0}\\nY=0,S=1: {count_y0_s1}\\nY=1,S=0: {count_y1_s0}\\nY=1,S=1: {count_y1_s1}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
